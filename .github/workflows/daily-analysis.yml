name: Daily Stock Analysis

on:
  schedule:
    # Run at 21:00 UTC (5:00 AM Beijing Time, Tuesday-Saturday)
    - cron: '0 21 * * 1-5'
  workflow_dispatch:
    inputs:
      mode:
        description: 'Analysis mode'
        default: 'analyze'
        type: choice
        options:
          - analyze
          - discover
          - portfolio
          - ibkr_portfolio
      stocks:
        description: 'Stock symbols (comma-separated, for analyze mode)'
        required: false
      analysis_type:
        description: 'Analysis type'
        default: 'full'
        type: choice
        options:
          - quick
          - full
          - deep
      portfolio:
        description: 'Portfolio holdings (JSON format: [{"symbol":"AAPL","shares":10,"avg_cost":150}])'
        required: false

jobs:
  analyze:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -e .

      - name: Create data directory
        run: mkdir -p data reports

      - name: Initialize portfolio from secrets
        if: github.event.inputs.mode == 'portfolio'
        run: |
          if [ -n "${{ secrets.PORTFOLIO_HOLDINGS }}" ]; then
            echo "${{ secrets.PORTFOLIO_HOLDINGS }}" > data/portfolio.json
            python -c "
            import json
            from ai_stock_analyst.agents.portfolio_analysis import add_holding
            with open('data/portfolio.json') as f:
                holdings = json.load(f)
            for h in holdings:
                add_holding(h['symbol'], h['shares'], h['avg_cost'])
            print(f'Loaded {len(holdings)} holdings')
            "
          else
            echo "No PORTFOLIO_HOLDINGS secret found"
          fi

      - name: Run stock analysis
        if: github.event.inputs.mode == 'analyze' || github.event.inputs.mode == ''
        env:
          PYTHONPATH: ${{ github.workspace }}
          DATABASE_URL: sqlite:///./data/stock_analyzer.db
          BAILIAN_API_KEY: ${{ secrets.BAILIAN_API_KEY }}
          BAILIAN_REGION: ${{ secrets.BAILIAN_REGION || 'beijing' }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          LLM_PRIMARY: ${{ secrets.LLM_PRIMARY || vars.LLM_PRIMARY || 'bailian' }}
          LLM_FALLBACK: ${{ secrets.LLM_FALLBACK || vars.LLM_FALLBACK || 'gemini' }}
          STOCK_LIST: ${{ github.event.inputs.stocks || vars.STOCK_LIST || secrets.STOCK_LIST || 'AAPL,TSLA,NVDA,MSFT,GOOGL,AMZN,META' }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          DINGTALK_WEBHOOK_URL: ${{ secrets.DINGTALK_WEBHOOK_URL }}
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          WECHAT_WORK_WEBHOOK_URL: ${{ secrets.WECHAT_WORK_WEBHOOK_URL }}
        run: |
          python -c "from ai_stock_analyst.data import fetch_stock_price; print('Import test OK')"
          stock-analyze --type ${{ github.event.inputs.analysis_type || 'full' }}

      - name: Discover trending stocks
        if: github.event.inputs.mode == 'discover'
        env:
          PYTHONPATH: ${{ github.workspace }}
          DATABASE_URL: sqlite:///./data/stock_analyzer.db
          BAILIAN_API_KEY: ${{ secrets.BAILIAN_API_KEY }}
          BAILIAN_REGION: ${{ secrets.BAILIAN_REGION || 'beijing' }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          DINGTALK_WEBHOOK_URL: ${{ secrets.DINGTALK_WEBHOOK_URL }}
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        run: stock-analyze --discover

      - name: Analyze portfolio
        if: github.event.inputs.mode == 'portfolio'
        env:
          PYTHONPATH: ${{ github.workspace }}
          DATABASE_URL: sqlite:///./data/stock_analyzer.db
          BAILIAN_API_KEY: ${{ secrets.BAILIAN_API_KEY }}
          BAILIAN_REGION: ${{ secrets.BAILIAN_REGION || 'beijing' }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          DINGTALK_WEBHOOK_URL: ${{ secrets.DINGTALK_WEBHOOK_URL }}
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        run: stock-analyze --portfolio

      - name: Sync IBKR holdings and analyze portfolio
        if: github.event.inputs.mode == 'ibkr_portfolio'
        env:
          PYTHONPATH: ${{ github.workspace }}
          DATABASE_URL: sqlite:///./data/stock_analyzer.db
          BAILIAN_API_KEY: ${{ secrets.BAILIAN_API_KEY }}
          BAILIAN_REGION: ${{ secrets.BAILIAN_REGION || 'beijing' }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          DINGTALK_WEBHOOK_URL: ${{ secrets.DINGTALK_WEBHOOK_URL }}
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          IBKR_HOST: ${{ secrets.IBKR_HOST }}
          IBKR_PORT: ${{ secrets.IBKR_PORT }}
          IBKR_CLIENT_ID: ${{ secrets.IBKR_CLIENT_ID }}
          IBKR_ACCOUNT: ${{ secrets.IBKR_ACCOUNT }}
          IBKR_API_MODE: ${{ secrets.IBKR_API_MODE || vars.IBKR_API_MODE || 'auto' }}
          IBKR_CPAPI_BASE_URL: ${{ secrets.IBKR_CPAPI_BASE_URL || vars.IBKR_CPAPI_BASE_URL || 'https://localhost:5000/v1/api' }}
          IBKR_CPAPI_VERIFY_SSL: ${{ secrets.IBKR_CPAPI_VERIFY_SSL || vars.IBKR_CPAPI_VERIFY_SSL || 'false' }}
          IBKR_CPAPI_TIMEOUT: ${{ secrets.IBKR_CPAPI_TIMEOUT || vars.IBKR_CPAPI_TIMEOUT || '12' }}
        run: |
          if [ "${IBKR_API_MODE}" != "cpapi" ]; then
            pip install ib_async
          fi
          stock-analyze --sync-ibkr-holdings --portfolio --strict-ibkr

      - name: Run backtest smoke
        if: always()
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          python scripts/backtest_strategy.py --symbols SPY --period 6mo --output-dir reports

      - name: Upload analysis reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: analysis-reports-${{ github.run_number }}-${{ github.run_attempt }}
          path: |
            reports/
            data/*.db
          retention-days: 30
